{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_AttentionBased.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vMZKDxP2boH"
      },
      "source": [
        "### Sequence to Sequence attention model for machine translation\n",
        "### This notebook trains a sequence to sequence (seq2seq) model with two different attentions implemented for Spanish to English translation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R8nOjZK2QmA",
        "outputId": "0f0bc0f1-a400-4110-a93b-e6f1b8ea007e"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3z9FhRz2kk9"
      },
      "source": [
        "#### Load data set\n",
        "#### Clean the sentences by removing special characters.\n",
        "#### Add a start and end token to each sentence.\n",
        "#### Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
        "#### Pad each sentence to a maximum length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYSiLwZp2jnD",
        "outputId": "6b92fe1f-4421-450c-e6da-a76c287991fc"
      },
      "source": [
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aovEvEz92Qo_"
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\",\"¿\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  # remove extra space\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaX2BZLw2QuC",
        "outputId": "cebf6a56-1801-4683-ceb4-dc87c84a9a5c"
      },
      "source": [
        "en_sentence = u\"May I borrow this @ book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode(\"UTF-8\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "<start> ¿ puedo tomar prestado este libro ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2XA7Yag2Qw_",
        "outputId": "82e73a69-0343-4a0e-f222-bcec3d4ab737"
      },
      "source": [
        "# Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "  return zip(*word_pairs)\n",
        "\n",
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])\n",
        "print(len(en), len(sp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n",
            "118964 118964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwT66C9J2Q2y"
      },
      "source": [
        "# Tokenize the sentence into list of words(integers) and pad the sequence to the same length\n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4osaAxpp2Q5u"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bsb61NTl2Q8i",
        "outputId": "4cd77057-3bdf-4a14-e653-bf82c3c26d50"
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "print(max_length_targ, max_length_inp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLi-cF3l2Q_W",
        "outputId": "15f71e72-36a1-4b2f-8fe4-fff704f8665d"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n",
        "print(input_tensor_train[0])\n",
        "print(target_tensor_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n",
            "[   1    6  315 1039   21  175    5    2    0    0    0    0    0    0\n",
            "    0    0]\n",
            "[  1  52 154   8   9 165   7   2   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_Ydrump3D5V"
      },
      "source": [
        "#### Create a tf.data datasest\n",
        "#### The tf.data.Dataset API supports writing descriptive and efficient input pipelines. Dataset usage follows a common pattern:\n",
        "#### Create a source dataset from your input data.\n",
        "#### Apply dataset transformations to preprocess the data.\n",
        "#### Iterate over the dataset and process the elements.\n",
        "#### Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc_4oGi6-kfh",
        "outputId": "88534d05-51db-48f1-e57a-9db68207aadb"
      },
      "source": [
        "![picture](https://drive.google.com/file/d/1u4tMhmBAd9SNQZ9TScW0p4s0gbdqhJ1S/view?usp=sharing)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `https://drive.google.com/file/d/1u4tMhmBAd9SNQZ9TScW0p4s0gbdqhJ1S/view?usp=sharing'\n",
            "/bin/bash: -c: line 0: `[picture](https://drive.google.com/file/d/1u4tMhmBAd9SNQZ9TScW0p4s0gbdqhJ1S/view?usp=sharing)'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZJ2dUvC_HWF"
      },
      "source": [
        "![picture](https://drive.google.com/file/d/1u4tMhmBAd9SNQZ9TScW0p4s0gbdqhJ1S/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yir9JPLt2RCe",
        "outputId": "2d202b67-83f3-41a0-974b-3a77778fc822"
      },
      "source": [
        "# Configuration \n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "steps_per_epoch_val = len(input_tensor_val)//BATCH_SIZE\n",
        "embedding_dim = 256  # for word embedding\n",
        "units = 1024  # dimensionality of the output space of RNN\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val)).shuffle(BUFFER_SIZE)\n",
        "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fueGF9qe3Rxn"
      },
      "source": [
        "#### Basic seq2seq model: encoder and decoder\n",
        "#### Model groups layers into an object with training and inference features. Two ways to define tf model:\n",
        "\n",
        "#### Basic sequence to sequence model without attention: alt text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU3xTNav21fP"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,  # Whether to return the last output in the output sequence, or the full sequence. \n",
        "                                   return_state=True,  # Whether to return the last state in addition to the output.\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGxpOeuR21iF",
        "outputId": "b6d17f6f-c591-450b-de2d-525c12ab3888"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA29_rpd21ng"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "    return x, state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7qVwvbB21qs",
        "outputId": "357e4a4f-a344-42e2-feb4-e3330056f257"
      },
      "source": [
        "tf.reshape([[1,2,3],[4,5,6]], (-1, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[1, 2],\n",
              "       [3, 4],\n",
              "       [5, 6]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTWGEkxD21uZ",
        "outputId": "06dac119-591e-475d-d13a-bf044988d9d4"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUQm51ib3i7J"
      },
      "source": [
        "class DotProductAttention(tf.keras.layers.Layer):\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # inner product, score shape == (batch_size, max_length, 1)\n",
        "    score = query_with_time_axis * values\n",
        "    score = tf.reduce_sum(score, axis=2)\n",
        "    score = tf.expand_dims(score, 2)\n",
        "    \n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9JfdkGu3i_C",
        "outputId": "4f9489a6-174f-4ca7-b566-917df0275989"
      },
      "source": [
        "attention_layer = DotProductAttention()\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Txp6seN3jC6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvz3e0mj3jG0"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(query_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_lu56JN3jLG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyVCnaFn3jOn"
      },
      "source": [
        "class DecoderWithAttention(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, attention_layer = None):\n",
        "    super(DecoderWithAttention, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = attention_layer\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "    attention_weights = None\n",
        "    \n",
        "    if self.attention:\n",
        "      # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "      context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "      # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "      x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQfUfyHA3jT5"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0)) \n",
        "  loss_ = loss_object(real, pred)\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtWUs-sq3jX3",
        "outputId": "63deb39e-7475-4663-97aa-2d52378a4a71"
      },
      "source": [
        "print(loss_object([1,2],[[0,0.6,0.3,0.1],[0,0.6,0.3,0.1]]))\n",
        "print(loss_function([1,2],[[0,0.6,0.3,0.1],[0,0.6,0.3,0.1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1.063386  1.3633859], shape=(2,), dtype=float32)\n",
            "tf.Tensor(1.2133859, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32NObrq-4F9Y"
      },
      "source": [
        "# Training\n",
        "#### @tf.function In TensorFlow 2, eager execution is turned on by default. The user interface is intuitive and flexible (running one-off operations is much easier and faster), but this can come at the expense of performance and deployability. It is recommended to debug in eager mode, then decorate with @tf.function for better performance.\n",
        "#### In TensorFlow 2.0, users should refactor their code into smaller functions which are called as needed. In general, it's not necessary to decorate each of these smaller functions with tf.function; only use tf.function to decorate high-level computations - for example, one step of training, or the forward pass of your model.\n",
        "#### TensorFlow provides the tf.GradientTape API for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually tf.Variables. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkBU1iiU3jd_"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "def get_train_step_func():\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(inp, targ, enc_hidden, encoder, decoder):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape: # for automatic differentiation\n",
        "      enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "      dec_hidden = enc_hidden\n",
        "\n",
        "      dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "      # Teacher forcing - feeding the target as the next input\n",
        "      for t in range(1, targ.shape[1]):\n",
        "        # passing enc_output to the decoder\n",
        "        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "        loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "        # using teacher forcing\n",
        "        dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss\n",
        "    \n",
        "  return train_step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4xhmH1z4N7W"
      },
      "source": [
        "def caculate_validation_loss(inp, targ, enc_hidden, encoder, decoder):\n",
        "  loss = 0\n",
        "  enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "  # Teacher forcing - feeding the target as the next input\n",
        "  for t in range(1, targ.shape[1]):\n",
        "    predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "    loss += loss_function(targ[:, t], predictions)\n",
        "    dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  loss = loss / int(targ.shape[1])\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyqOb7uu4OYZ"
      },
      "source": [
        "def training_seq2seq(epochs, attention):\n",
        "  encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "  decoder = DecoderWithAttention(vocab_tar_size, embedding_dim, units, BATCH_SIZE, attention)\n",
        "  train_step_func = get_train_step_func()\n",
        "  training_loss = []\n",
        "  validation_loss = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "      batch_loss = train_step_func(inp, targ, enc_hidden, encoder, decoder)\n",
        "      total_loss += batch_loss\n",
        "\n",
        "      if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss))\n",
        "        \n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_val_loss = 0\n",
        "    for (batch, (inp, targ)) in enumerate(validation_dataset.take(steps_per_epoch)):\n",
        "      val_loss = caculate_validation_loss(inp, targ, enc_hidden, encoder, decoder)\n",
        "      total_val_loss += val_loss\n",
        "\n",
        "    training_loss.append(total_loss / steps_per_epoch)\n",
        "    validation_loss.append(total_val_loss / steps_per_epoch_val)\n",
        "    print('Epoch {} Loss {:.4f} Validation Loss {:.4f}'.format(epoch + 1,\n",
        "                                        training_loss[-1], validation_loss[-1]))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "  return encoder, decoder, training_loss, validation_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ54SNVo6Y4u"
      },
      "source": [
        "# Training seq2seq without attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqfYpYif4OdF",
        "outputId": "26c7beb2-3e61-4d75-9898-5b51ad2b73c4"
      },
      "source": [
        "epochs = 10\n",
        "attention = None\n",
        "\n",
        "print(\"Running seq2seq model without attention\")\n",
        "encoder, decoder, training_loss, validation_loss = training_seq2seq(epochs, attention)\n",
        "\n",
        "tloss = training_loss\n",
        "vloss = validation_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running seq2seq model without attention\n",
            "Epoch 1 Batch 0 Loss 4.6748\n",
            "Epoch 1 Batch 100 Loss 1.9090\n",
            "Epoch 1 Batch 200 Loss 1.5966\n",
            "Epoch 1 Batch 300 Loss 1.4434\n",
            "Epoch 1 Loss 1.8035 Validation Loss 1.3420\n",
            "Time taken for 1 epoch 37.54328489303589 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.1774\n",
            "Epoch 2 Batch 100 Loss 1.1825\n",
            "Epoch 2 Batch 200 Loss 1.0722\n",
            "Epoch 2 Batch 300 Loss 0.9067\n",
            "Epoch 2 Loss 1.0631 Validation Loss 1.0422\n",
            "Time taken for 1 epoch 30.755150318145752 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.8281\n",
            "Epoch 3 Batch 100 Loss 0.8404\n",
            "Epoch 3 Batch 200 Loss 0.7021\n",
            "Epoch 3 Batch 300 Loss 0.6920\n",
            "Epoch 3 Loss 0.7172 Validation Loss 0.9053\n",
            "Time taken for 1 epoch 30.81467914581299 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.4220\n",
            "Epoch 4 Batch 100 Loss 0.4545\n",
            "Epoch 4 Batch 200 Loss 0.4657\n",
            "Epoch 4 Batch 300 Loss 0.5227\n",
            "Epoch 4 Loss 0.4773 Validation Loss 0.8342\n",
            "Time taken for 1 epoch 30.40312147140503 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.3079\n",
            "Epoch 5 Batch 100 Loss 0.2585\n",
            "Epoch 5 Batch 200 Loss 0.2499\n",
            "Epoch 5 Batch 300 Loss 0.2992\n",
            "Epoch 5 Loss 0.3137 Validation Loss 0.8090\n",
            "Time taken for 1 epoch 30.378618717193604 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.1822\n",
            "Epoch 6 Batch 100 Loss 0.1987\n",
            "Epoch 6 Batch 200 Loss 0.2013\n",
            "Epoch 6 Batch 300 Loss 0.2207\n",
            "Epoch 6 Loss 0.2064 Validation Loss 0.8085\n",
            "Time taken for 1 epoch 30.31775164604187 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1220\n",
            "Epoch 7 Batch 100 Loss 0.1706\n",
            "Epoch 7 Batch 200 Loss 0.1316\n",
            "Epoch 7 Batch 300 Loss 0.1948\n",
            "Epoch 7 Loss 0.1410 Validation Loss 0.8121\n",
            "Time taken for 1 epoch 30.277885913848877 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1035\n",
            "Epoch 8 Batch 100 Loss 0.1018\n",
            "Epoch 8 Batch 200 Loss 0.1186\n",
            "Epoch 8 Batch 300 Loss 0.0841\n",
            "Epoch 8 Loss 0.1018 Validation Loss 0.8261\n",
            "Time taken for 1 epoch 30.24387264251709 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0686\n",
            "Epoch 9 Batch 100 Loss 0.0607\n",
            "Epoch 9 Batch 200 Loss 0.0808\n",
            "Epoch 9 Batch 300 Loss 0.0844\n",
            "Epoch 9 Loss 0.0815 Validation Loss 0.8267\n",
            "Time taken for 1 epoch 30.174956560134888 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0593\n",
            "Epoch 10 Batch 100 Loss 0.0799\n",
            "Epoch 10 Batch 200 Loss 0.0576\n",
            "Epoch 10 Batch 300 Loss 0.0728\n",
            "Epoch 10 Loss 0.0673 Validation Loss 0.8465\n",
            "Time taken for 1 epoch 30.247004985809326 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag5ybt2m4a-P"
      },
      "source": [
        "# Training seq2seq with dot product attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pna5zPj4Ohr",
        "outputId": "b16d2888-8108-455e-ec82-8dba84cb384f"
      },
      "source": [
        "attention = DotProductAttention()\n",
        "print(\"Running seq2seq model with dot product attention\")\n",
        "encoder_dp, decoder_dp, training_loss, validation_loss = training_seq2seq(epochs, attention)\n",
        "\n",
        "tloss = np.vstack((tloss, training_loss))\n",
        "vloss = np.vstack((vloss, validation_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running seq2seq model with dot product attention\n",
            "Epoch 1 Batch 0 Loss 4.6020\n",
            "Epoch 1 Batch 100 Loss 2.3719\n",
            "Epoch 1 Batch 200 Loss 1.8848\n",
            "Epoch 1 Batch 300 Loss 1.7822\n",
            "Epoch 1 Loss 2.2982 Validation Loss 1.6660\n",
            "Time taken for 1 epoch 42.10916471481323 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4742\n",
            "Epoch 2 Batch 100 Loss 1.3902\n",
            "Epoch 2 Batch 200 Loss 1.3123\n",
            "Epoch 2 Batch 300 Loss 1.2529\n",
            "Epoch 2 Loss 1.3757 Validation Loss 1.3771\n",
            "Time taken for 1 epoch 34.258906841278076 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.1034\n",
            "Epoch 3 Batch 100 Loss 1.0286\n",
            "Epoch 3 Batch 200 Loss 1.0179\n",
            "Epoch 3 Batch 300 Loss 0.9118\n",
            "Epoch 3 Loss 1.0617 Validation Loss 1.2145\n",
            "Time taken for 1 epoch 34.25757074356079 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.8115\n",
            "Epoch 4 Batch 100 Loss 0.9374\n",
            "Epoch 4 Batch 200 Loss 0.8768\n",
            "Epoch 4 Batch 300 Loss 0.9101\n",
            "Epoch 4 Loss 0.8465 Validation Loss 1.1165\n",
            "Time taken for 1 epoch 34.25483560562134 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.6526\n",
            "Epoch 5 Batch 100 Loss 0.7334\n",
            "Epoch 5 Batch 200 Loss 0.6811\n",
            "Epoch 5 Batch 300 Loss 0.5890\n",
            "Epoch 5 Loss 0.6891 Validation Loss 1.0540\n",
            "Time taken for 1 epoch 34.08797645568848 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.5751\n",
            "Epoch 6 Batch 100 Loss 0.4875\n",
            "Epoch 6 Batch 200 Loss 0.6401\n",
            "Epoch 6 Batch 300 Loss 0.5954\n",
            "Epoch 6 Loss 0.5646 Validation Loss 1.0005\n",
            "Time taken for 1 epoch 34.1778838634491 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.4089\n",
            "Epoch 7 Batch 100 Loss 0.4293\n",
            "Epoch 7 Batch 200 Loss 0.4627\n",
            "Epoch 7 Batch 300 Loss 0.4226\n",
            "Epoch 7 Loss 0.4707 Validation Loss 0.9671\n",
            "Time taken for 1 epoch 33.84042954444885 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.3503\n",
            "Epoch 8 Batch 100 Loss 0.3522\n",
            "Epoch 8 Batch 200 Loss 0.4208\n",
            "Epoch 8 Batch 300 Loss 0.4689\n",
            "Epoch 8 Loss 0.3963 Validation Loss 0.9529\n",
            "Time taken for 1 epoch 33.81192064285278 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.3464\n",
            "Epoch 9 Batch 100 Loss 0.3025\n",
            "Epoch 9 Batch 200 Loss 0.2928\n",
            "Epoch 9 Batch 300 Loss 0.3862\n",
            "Epoch 9 Loss 0.3357 Validation Loss 0.9381\n",
            "Time taken for 1 epoch 34.45353388786316 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.2825\n",
            "Epoch 10 Batch 100 Loss 0.2447\n",
            "Epoch 10 Batch 200 Loss 0.3249\n",
            "Epoch 10 Batch 300 Loss 0.3525\n",
            "Epoch 10 Loss 0.2875 Validation Loss 0.9277\n",
            "Time taken for 1 epoch 34.72526526451111 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmW3BU2Q4reF"
      },
      "source": [
        "# Training seq2seq with Bahdanau attention¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co5u0tEo4OnK",
        "outputId": "a31c3186-4f68-416a-adcb-878d57a633c1"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "attention = BahdanauAttention(units)\n",
        "print(\"Running seq2seq model with Bahdanau attention\")\n",
        "encoder_bah, decoder_bah, training_loss, validation_loss = training_seq2seq(epochs, attention)\n",
        "\n",
        "tloss = np.vstack((tloss, training_loss))\n",
        "vloss = np.vstack((vloss, validation_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running seq2seq model with Bahdanau attention\n",
            "Epoch 1 Batch 0 Loss 4.7967\n",
            "Epoch 1 Batch 100 Loss 1.8333\n",
            "Epoch 1 Batch 200 Loss 1.6482\n",
            "Epoch 1 Batch 300 Loss 1.2940\n",
            "Epoch 1 Loss 1.7003 Validation Loss 1.2018\n",
            "Time taken for 1 epoch 51.86678433418274 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.9175\n",
            "Epoch 2 Batch 100 Loss 0.8615\n",
            "Epoch 2 Batch 200 Loss 0.9505\n",
            "Epoch 2 Batch 300 Loss 0.8941\n",
            "Epoch 2 Loss 0.8752 Validation Loss 0.9140\n",
            "Time taken for 1 epoch 43.20350956916809 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.4952\n",
            "Epoch 3 Batch 100 Loss 0.5564\n",
            "Epoch 3 Batch 200 Loss 0.5878\n",
            "Epoch 3 Batch 300 Loss 0.4989\n",
            "Epoch 3 Loss 0.5113 Validation Loss 0.8162\n",
            "Time taken for 1 epoch 43.01873302459717 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.3042\n",
            "Epoch 4 Batch 100 Loss 0.2762\n",
            "Epoch 4 Batch 200 Loss 0.3203\n",
            "Epoch 4 Batch 300 Loss 0.3070\n",
            "Epoch 4 Loss 0.3059 Validation Loss 0.7858\n",
            "Time taken for 1 epoch 43.05774998664856 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1847\n",
            "Epoch 5 Batch 100 Loss 0.1588\n",
            "Epoch 5 Batch 200 Loss 0.1681\n",
            "Epoch 5 Batch 300 Loss 0.1780\n",
            "Epoch 5 Loss 0.1935 Validation Loss 0.7826\n",
            "Time taken for 1 epoch 43.135497093200684 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.1224\n",
            "Epoch 6 Batch 100 Loss 0.1106\n",
            "Epoch 6 Batch 200 Loss 0.1234\n",
            "Epoch 6 Batch 300 Loss 0.1027\n",
            "Epoch 6 Loss 0.1301 Validation Loss 0.7858\n",
            "Time taken for 1 epoch 43.086588859558105 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.0835\n",
            "Epoch 7 Batch 100 Loss 0.0869\n",
            "Epoch 7 Batch 200 Loss 0.0988\n",
            "Epoch 7 Batch 300 Loss 0.0773\n",
            "Epoch 7 Loss 0.0945 Validation Loss 0.7909\n",
            "Time taken for 1 epoch 43.145376443862915 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0777\n",
            "Epoch 8 Batch 100 Loss 0.0690\n",
            "Epoch 8 Batch 200 Loss 0.0873\n",
            "Epoch 8 Batch 300 Loss 0.0884\n",
            "Epoch 8 Loss 0.0750 Validation Loss 0.8001\n",
            "Time taken for 1 epoch 43.23190379142761 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0328\n",
            "Epoch 9 Batch 100 Loss 0.0482\n",
            "Epoch 9 Batch 200 Loss 0.0621\n",
            "Epoch 9 Batch 300 Loss 0.0721\n",
            "Epoch 9 Loss 0.0627 Validation Loss 0.8130\n",
            "Time taken for 1 epoch 42.99381422996521 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0263\n",
            "Epoch 10 Batch 100 Loss 0.0535\n",
            "Epoch 10 Batch 200 Loss 0.0534\n",
            "Epoch 10 Batch 300 Loss 0.0677\n",
            "Epoch 10 Loss 0.0558 Validation Loss 0.8164\n",
            "Time taken for 1 epoch 42.998420000076294 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "tzMM7MZf4Org",
        "outputId": "32b3a8ae-ba14-4253-df18-7f482fc57467"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ax = plt.subplot(111) \n",
        "t = np.arange(1, epochs+1)\n",
        "\n",
        "for i in range(0, vloss.shape[0]):\n",
        "  line, = plt.plot(t, vloss[i,:], lw=2)\n",
        "\n",
        "ax.legend(('No attention', 'Dot product', 'Bahdanau'))\n",
        "ax.set_title(\"Validation loss\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Validation loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neej4zs846FJ"
      },
      "source": [
        "# Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqayyYms4Owz"
      },
      "source": [
        "def translate(sentence, encoder, decoder):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    # until the predicted word is <end>.\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence\n",
        "\n",
        "    # the predicted ID is fed back into the model, no teacher forcing.\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyafI3e-4O3F",
        "outputId": "4520da3b-9434-4d4a-bf4c-e0450f3bf0b8"
      },
      "source": [
        "result, sentence = translate(u'esta es mi vida.', encoder_bah, decoder_bah)\n",
        "print('Input: %s' % (sentence))\n",
        "print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUi7dcnw4O8v",
        "outputId": "2f91f7e0-c27f-484a-bd8c-d3c66985305c"
      },
      "source": [
        "result, sentence = translate(u'esta es mi vida.', encoder_dp, decoder_dp)\n",
        "print('Input: %s' % (sentence))\n",
        "print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAe7K1Hh4PDO",
        "outputId": "6fe1981a-1aef-4c5d-8c3e-072e4e39077e"
      },
      "source": [
        "result, sentence = translate(u'¿todavia estan en casa?', encoder_bah, decoder_bah)\n",
        "print('Input: %s' % (sentence))\n",
        "print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ¿ todavia estan en casa ? <end>\n",
            "Predicted translation: are you still at home ? <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9_SovDv5FW4"
      },
      "source": [
        "#Next Steps\n",
        "## Training on larger dataset\n",
        "## Model tuning\n",
        "## Try out other attention scores such as multiplicative\n",
        "## Train on other seq2seq tasks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h1whsQc4PJn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}